{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:107004\n",
      "training:90953 validation:16051\n"
     ]
    }
   ],
   "source": [
    "# dataset param\n",
    "DATA_PATH = \"../output_mask2/\"\n",
    "IMG_SIZE = (224, 224)\n",
    "NCLASS = 4\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.15\n",
    "NUMWORKERS = 4\n",
    "\n",
    "# model training hparam\n",
    "EPOCH = 10\n",
    "LR = 1e-3\n",
    "FOCAL_GAMMA = 1\n",
    "FOCAL_ALPHA = None\n",
    "#FOCAL_ALPHA = [0.15, 1, 1, 1]\n",
    "\n",
    "# eval param\n",
    "PLOT_PATH = \"plots_classification/\"\n",
    "MODEL_PATH = \"model_classification/\"\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#DEVICE = 'cpu'\n",
    "\n",
    "# augmentations                         \n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(p=0.2),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# creating dataset and loader using image folder\n",
    "full_dataset = ImageFolder(DATA_PATH, transform=train_transform)\n",
    "full_dataset_test = ImageFolder(DATA_PATH, transform=test_transform)\n",
    "\n",
    "data_idx = np.arange(len(full_dataset))\n",
    "train_idx, val_idx = train_test_split(data_idx, test_size=VAL_SPLIT, random_state=100)\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "val_dataset = Subset(full_dataset_test, val_idx)\n",
    "print(f\"total:{len(full_dataset)}\\ntraining:{len(train_dataset)} validation:{len(val_dataset)}\")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True, num_workers=NUMWORKERS, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, BATCH_SIZE, num_workers=NUMWORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics.functional as MF\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def model_train(dataloader, model, loss_func, optimizer, current_epoch):\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    avg_prec = 0\n",
    "    avg_rec = 0\n",
    "    cur_len = 1\n",
    "    \n",
    "    model.train()\n",
    "    prog_bar = tqdm(dataloader, desc=f'Epoch: {current_epoch}', unit='batch')\n",
    "    for x,y in prog_bar:\n",
    "        pred = model(x.to(DEVICE))\n",
    "        target = y.to(DEVICE)\n",
    "        #pred = F.softmax(pred, dim=1)\n",
    "        #print(pred.size())\n",
    "        loss = loss_func(pred, target)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # eval\n",
    "        acc = MF.accuracy(pred, target, task='multiclass', average='macro', num_classes=NCLASS, top_k=1, validate_args=False)\n",
    "        prec = MF.precision(pred, target, task='multiclass', average='macro', num_classes=NCLASS, top_k=1, validate_args=False)\n",
    "        rec = MF.recall(pred, target, task='multiclass', average='macro', num_classes=NCLASS, top_k=1, validate_args=False)\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "        avg_acc += acc\n",
    "        avg_prec += prec\n",
    "        avg_rec += rec\n",
    "\n",
    "        prog_bar.set_postfix_str(f'train accuracy:{avg_acc/cur_len:.3f}, loss:{avg_loss/cur_len:.3f}, prec:{avg_prec/cur_len:.3f}, rec:{avg_rec/cur_len:.3f}')\n",
    "        cur_len += 1\n",
    "    \n",
    "    # count avg\n",
    "    data_len = len(dataloader)\n",
    "    avg_loss /= data_len\n",
    "    avg_acc /= data_len\n",
    "    avg_prec /= data_len\n",
    "    avg_rec /= data_len\n",
    "\n",
    "    f1 = (2 * avg_prec * avg_rec) / (avg_prec + avg_rec)\n",
    "\n",
    "    history = {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy' : avg_acc,\n",
    "        'precision' : avg_prec,\n",
    "        'recall' : avg_rec,\n",
    "        'f1_score' : f1\n",
    "    }\n",
    "\n",
    "    return history\n",
    "\n",
    "def model_predict(dataloader, model, loss_func, silent=True, save_prediction=False):\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    avg_prec = 0\n",
    "    avg_rec = 0\n",
    "    \n",
    "    predictions = torch.tensor([]).to(DEVICE)\n",
    "    targets = torch.tensor([], dtype=torch.int64).to(DEVICE)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,y in tqdm(dataloader, desc='Predicting', unit='batch', disable=silent):\n",
    "            pred = model(x.to(DEVICE))\n",
    "            target = y.to(DEVICE)\n",
    "            #pred = F.softmax(pred, dim=1)\n",
    "            loss = loss_func(pred, target)\n",
    "\n",
    "            acc = MF.accuracy(pred, target, task='multiclass', average='macro', num_classes=NCLASS, top_k=1, validate_args=False)\n",
    "            prec = MF.precision(pred, target, task='multiclass', average='macro', num_classes=NCLASS, top_k=1, validate_args=False)\n",
    "            rec = MF.recall(pred, target, task='multiclass', average='macro', num_classes=NCLASS, top_k=1, validate_args=False)\n",
    "            \n",
    "            avg_loss += loss.item()\n",
    "            avg_acc += acc\n",
    "            avg_prec += prec\n",
    "            avg_rec += rec\n",
    "            \n",
    "            predictions = torch.cat((predictions, pred), dim=0)\n",
    "            targets = torch.cat((targets, target), dim=0)\n",
    "        \n",
    "    data_len = len(dataloader)\n",
    "    avg_loss /= data_len\n",
    "    avg_acc /= data_len\n",
    "    avg_prec /= data_len\n",
    "    avg_rec /= data_len\n",
    "\n",
    "    f1 = (2 * avg_prec * avg_rec) / (avg_prec + avg_rec)\n",
    "    \n",
    "    rocauc = MF.auroc(predictions, targets, task='multiclass', num_classes=NCLASS, average='macro')\n",
    "    if not silent:\n",
    "        print(f\"roc-auc:{rocauc.item()}\")\n",
    "\n",
    "    result = {\n",
    "        'predictions' : predictions if save_prediction else None,\n",
    "        'targets' : targets if save_prediction else None,\n",
    "        'rocauc' : rocauc,\n",
    "        'loss': avg_loss,\n",
    "        'accuracy' : avg_acc,\n",
    "        'precision' : avg_prec,\n",
    "        'recall' : avg_rec,\n",
    "        'f1_score' : f1\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "def add_history(history_list, train_history, val_result):\n",
    "    history_list['loss'].append(train_history['loss'])\n",
    "    history_list['acc'].append(train_history['accuracy'].item())\n",
    "    history_list['prec'].append(train_history['precision'].item())\n",
    "    history_list['rec'].append(train_history['recall'].item())\n",
    "    history_list['f1'].append(train_history['f1_score'].item())\n",
    "\n",
    "    history_list['val_loss'].append(val_result['loss'])\n",
    "    history_list['val_acc'].append(val_result['accuracy'].item())\n",
    "    history_list['val_prec'].append(val_result['precision'].item())\n",
    "    history_list['val_rec'].append(val_result['recall'].item())\n",
    "    history_list['val_f1'].append(val_result['f1_score'].item())\n",
    "    history_list['rocauc'].append(val_result['rocauc'].item())\n",
    "\n",
    "    return history_list\n",
    "\n",
    "def print_history(history:dict):\n",
    "    print(f\"training accuracy:{history['acc'][-1]:.3f}, precision:{history['prec'][-1]:.3f}, recall:{history['rec'][-1]:.3f}, f1:{history['f1'][-1]:.3f}\")\n",
    "    print(f\"validation accuracy:{history['val_acc'][-1]:.3f}, precision:{history['val_prec'][-1]:.3f}, recall:{history['val_rec'][-1]:.3f}, f1:{history['val_f1'][-1]:.3f}\")\n",
    "\n",
    "    #print(f\"\\nhighest training accuracy:{np.max(history['acc']):.3f} at epoch {np.argmax(history['acc'])+1}, precision:{np.max(history['prec']):.3f} at epoch {np.argmax(history['prec'])+1}, recall:{np.max(history['rec']):.3f} at epoch {np.argmax(history['rec'])+1}, f1:{np.max(history['f1']):.3f} at epoch {np.argmax(history['f1'])+1}\")\n",
    "    #print(f\"highest training accuracy:{np.max(history['acc']):.3f} at epoch {np.argmax(history['acc'])+1}, precision:{np.max(history['val_prec']):.3f} at epoch {np.argmax(history['val_prec'])+1}, recall:{np.max(history['val_rec']):.3f} at epoch {np.argmax(history['val_rec'])+1}, f1:{np.max(history['val_f1']):.3f} at epoch {np.argmax(history['val_f1'])+1}\")\n",
    "\n",
    "def plot_history(history:dict):\n",
    "    if not os.path.isdir(PLOT_PATH):\n",
    "        os.mkdir(PLOT_PATH)\n",
    "\n",
    "    label = {\n",
    "        'loss' : 'loss',\n",
    "        'acc' : 'accuracy',\n",
    "        'prec' : 'precision',\n",
    "        'rec' : 'recall',\n",
    "        'f1' : 'f1 score',\n",
    "    }\n",
    "    \n",
    "    keys = ['loss', 'acc', 'prec', 'rec', 'f1']\n",
    "    \n",
    "    for k in keys:\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(history[k])\n",
    "        plt.plot(history['val_'+k])\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel(label[k])\n",
    "        plt.legend(['training', 'validation'], loc='right')\n",
    "\n",
    "        save_path = os.path.join(PLOT_PATH, f\"{label[k]}.png\")\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focal loss\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1,1)\n",
    "\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()\n",
    "\n",
    "def freeze_layer(model, freeze_pct):\n",
    "    length = 0\n",
    "    names_list = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            length += 1\n",
    "        names_list.append(name)\n",
    "    names_list.append('end')\n",
    "\n",
    "    cur = 0\n",
    "    delay = False\n",
    "    a = [] #\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and 'weight' in name:\n",
    "            idx = names_list.index(name)\n",
    "            if 'bias' in names_list[idx+1]:\n",
    "                delay = True\n",
    "            cur += 1\n",
    "            param.requires_grad = False\n",
    "            a.append(name) #\n",
    "        elif param.requires_grad and 'bias' in name:\n",
    "            param.requires_grad = False\n",
    "            a.append(name) #\n",
    "            delay = False\n",
    "        \n",
    "        if (cur/length) >= freeze_pct and not delay:\n",
    "            break\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|████████| 2843/2843 [16:50<00:00,  2.81batch/s, train accuracy:0.436, loss:0.499, prec:0.500, rec:0.436]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [01:24<00:00,  5.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8589074611663818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|████████| 2843/2843 [11:24<00:00,  4.15batch/s, train accuracy:0.504, loss:0.439, prec:0.586, rec:0.504]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:46<00:00, 10.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8636717796325684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|████████| 2843/2843 [10:05<00:00,  4.70batch/s, train accuracy:0.531, loss:0.417, prec:0.613, rec:0.531]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:35<00:00, 13.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8751566410064697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|████████| 2843/2843 [10:07<00:00,  4.68batch/s, train accuracy:0.553, loss:0.398, prec:0.630, rec:0.553]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [01:41<00:00,  4.97batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8899364471435547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|████████| 2843/2843 [10:08<00:00,  4.67batch/s, train accuracy:0.570, loss:0.384, prec:0.643, rec:0.570]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:35<00:00, 14.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8984458446502686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|████████| 2843/2843 [10:07<00:00,  4.68batch/s, train accuracy:0.583, loss:0.374, prec:0.649, rec:0.583]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:35<00:00, 14.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9034420251846313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|████████| 2843/2843 [10:18<00:00,  4.60batch/s, train accuracy:0.592, loss:0.364, prec:0.659, rec:0.592]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:36<00:00, 13.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8974134922027588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|████████| 2843/2843 [11:23<00:00,  4.16batch/s, train accuracy:0.602, loss:0.356, prec:0.664, rec:0.602]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:36<00:00, 13.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9090593457221985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|████████| 2843/2843 [10:17<00:00,  4.60batch/s, train accuracy:0.606, loss:0.349, prec:0.669, rec:0.606]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:35<00:00, 14.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.908343493938446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|███████| 2843/2843 [10:17<00:00,  4.60batch/s, train accuracy:0.613, loss:0.343, prec:0.673, rec:0.613]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [01:44<00:00,  4.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9050074815750122\n",
      "training accuracy:0.613, precision:0.673, recall:0.613, f1:0.641\n",
      "validation accuracy:0.595, precision:0.669, recall:0.595, f1:0.630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "model = resnet50(weights='DEFAULT')\n",
    "model.fc = nn.Linear(2048, NCLASS)\n",
    "#freeze_layer(model, freeze_pct=0.2) # freeze layer\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "#loss_weight = torch.cuda.FloatTensor([0.15, 1.0, 1.0, 1.0])\n",
    "#ce = nn.CrossEntropyLoss(weight=loss_weight)\n",
    "focal = FocalLoss(gamma=FOCAL_GAMMA, alpha=FOCAL_ALPHA)\n",
    "adam = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "#adam = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
    "\n",
    "history = {\n",
    "    'loss' : [],\n",
    "    'acc' : [],\n",
    "    'prec' : [],\n",
    "    'rec' : [],\n",
    "    'f1' : [],\n",
    "    'val_loss' : [],\n",
    "    'val_acc' : [],\n",
    "    'val_prec' : [],\n",
    "    'val_rec' : [],\n",
    "    'val_f1' : [],\n",
    "    'rocauc' : []\n",
    "}\n",
    "\n",
    "# training loop\n",
    "for i in range(EPOCH):\n",
    "    train_history = model_train(train_dataloader, model, focal, adam, i+1)\n",
    "    val_result = model_predict(val_dataloader, model, focal, silent=False)\n",
    "\n",
    "    history = add_history(history, train_history, val_result)\n",
    "    #print(f\"validation accuracy:{val_result['accuracy']}, precision:{val_result['precision']}, recall:{val_result['recall']}, f1 score:{val_result['f1_score']}\")\n",
    "\n",
    "print_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet152-f82ba261.pth\" to C:\\Users\\Edy Irwansyah/.cache\\torch\\hub\\checkpoints\\resnet152-f82ba261.pth\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 230M/230M [09:27<00:00, 426kB/s]\n",
      "Epoch: 1: 100%|████████| 2843/2843 [25:54<00:00,  1.83batch/s, train accuracy:0.436, loss:0.733, prec:0.502, rec:0.436]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [02:23<00:00,  3.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8461800813674927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|████████| 2843/2843 [24:53<00:00,  1.90batch/s, train accuracy:0.510, loss:0.648, prec:0.596, rec:0.510]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [01:20<00:00,  6.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8671804666519165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|████████| 2843/2843 [24:51<00:00,  1.91batch/s, train accuracy:0.547, loss:0.611, prec:0.626, rec:0.547]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [01:20<00:00,  6.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8834278583526611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|████████| 2843/2843 [25:04<00:00,  1.89batch/s, train accuracy:0.567, loss:0.586, prec:0.643, rec:0.567]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [02:38<00:00,  3.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8924098014831543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|████████| 2843/2843 [24:52<00:00,  1.90batch/s, train accuracy:0.580, loss:0.565, prec:0.650, rec:0.580]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [01:20<00:00,  6.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8988258838653564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|████████| 2843/2843 [24:54<00:00,  1.90batch/s, train accuracy:0.591, loss:0.547, prec:0.660, rec:0.591]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [01:20<00:00,  6.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9064160585403442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|████████| 2843/2843 [24:53<00:00,  1.90batch/s, train accuracy:0.607, loss:0.534, prec:0.671, rec:0.607]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [02:51<00:00,  2.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9101715683937073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|████████| 2843/2843 [24:52<00:00,  1.91batch/s, train accuracy:0.612, loss:0.523, prec:0.673, rec:0.612]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [01:20<00:00,  6.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9115517735481262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|████████| 2843/2843 [24:53<00:00,  1.90batch/s, train accuracy:0.617, loss:0.514, prec:0.676, rec:0.617]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [01:20<00:00,  6.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9161149859428406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|███████| 2843/2843 [24:51<00:00,  1.91batch/s, train accuracy:0.628, loss:0.502, prec:0.687, rec:0.628]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [02:24<00:00,  3.48batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9169145822525024\n",
      "training accuracy:0.628, precision:0.687, recall:0.628, f1:0.656\n",
      "validation accuracy:0.610, precision:0.689, recall:0.610, f1:0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet152\n",
    "\n",
    "model = resnet152(weights='DEFAULT')\n",
    "model.fc = nn.Linear(2048, NCLASS)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "#loss_weight = torch.cuda.FloatTensor([0.15, 1.0, 1.0, 1.0])\n",
    "#ce = nn.CrossEntropyLoss(weight=loss_weight)\n",
    "focal = FocalLoss(gamma=FOCAL_GAMMA, alpha=FOCAL_ALPHA)\n",
    "adam = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "history = {\n",
    "    'loss' : [],\n",
    "    'acc' : [],\n",
    "    'prec' : [],\n",
    "    'rec' : [],\n",
    "    'f1' : [],\n",
    "    'val_loss' : [],\n",
    "    'val_acc' : [],\n",
    "    'val_prec' : [],\n",
    "    'val_rec' : [],\n",
    "    'val_f1' : [],\n",
    "    'rocauc' : []\n",
    "}\n",
    "\n",
    "# training loop\n",
    "for i in range(EPOCH):\n",
    "    train_history = model_train(train_dataloader, model, focal, adam, i+1)\n",
    "    val_result = model_predict(val_dataloader, model, focal, silent=False)\n",
    "\n",
    "    history = add_history(history, train_history, val_result)\n",
    "\n",
    "print_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|████████| 2843/2843 [06:46<00:00,  7.00batch/s, train accuracy:0.490, loss:0.465, prec:0.549, rec:0.490]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:46<00:00, 10.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8832800984382629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|████████| 2843/2843 [06:55<00:00,  6.84batch/s, train accuracy:0.562, loss:0.401, prec:0.624, rec:0.562]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:20<00:00, 24.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8950924873352051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|████████| 2843/2843 [06:44<00:00,  7.02batch/s, train accuracy:0.591, loss:0.375, prec:0.652, rec:0.591]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:19<00:00, 25.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9127956032752991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|████████| 2843/2843 [06:44<00:00,  7.04batch/s, train accuracy:0.611, loss:0.359, prec:0.666, rec:0.611]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:19<00:00, 25.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9079384803771973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|████████| 2843/2843 [07:02<00:00,  6.73batch/s, train accuracy:0.626, loss:0.344, prec:0.678, rec:0.626]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:19<00:00, 25.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9099280834197998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|████████| 2843/2843 [07:13<00:00,  6.56batch/s, train accuracy:0.632, loss:0.334, prec:0.682, rec:0.632]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:19<00:00, 25.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9195245504379272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|████████| 2843/2843 [07:40<00:00,  6.18batch/s, train accuracy:0.640, loss:0.325, prec:0.687, rec:0.640]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:19<00:00, 25.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9285060167312622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|████████| 2843/2843 [06:46<00:00,  6.99batch/s, train accuracy:0.648, loss:0.317, prec:0.693, rec:0.648]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:19<00:00, 25.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9266307353973389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|████████| 2843/2843 [06:46<00:00,  6.99batch/s, train accuracy:0.654, loss:0.311, prec:0.699, rec:0.654]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:19<00:00, 25.36batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9149775505065918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|███████| 2843/2843 [06:53<00:00,  6.88batch/s, train accuracy:0.655, loss:0.305, prec:0.700, rec:0.655]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:54<00:00,  9.13batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9302471876144409\n",
      "training accuracy:0.655, precision:0.700, recall:0.655, f1:0.677\n",
      "validation accuracy:0.683, precision:0.696, recall:0.683, f1:0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import efficientnet_b0\n",
    "\n",
    "model = efficientnet_b0(weights='DEFAULT')\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1280, NCLASS)\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "#loss_weight = torch.cuda.FloatTensor([0.15, 1.0, 1.0, 1.0])\n",
    "#ce = nn.CrossEntropyLoss(weight=loss_weight)\n",
    "focal = FocalLoss(gamma=FOCAL_GAMMA, alpha=FOCAL_ALPHA)\n",
    "adam = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "history = {\n",
    "    'loss' : [],\n",
    "    'acc' : [],\n",
    "    'prec' : [],\n",
    "    'rec' : [],\n",
    "    'f1' : [],\n",
    "    'val_loss' : [],\n",
    "    'val_acc' : [],\n",
    "    'val_prec' : [],\n",
    "    'val_rec' : [],\n",
    "    'val_f1' : [],\n",
    "    'rocauc' : []\n",
    "}\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    train_history = model_train(train_dataloader, model, focal, adam, i+1)\n",
    "    val_result = model_predict(val_dataloader, model, focal, silent=False)\n",
    "\n",
    "    history = add_history(history, train_history, val_result)\n",
    "\n",
    "print_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|████████| 2843/2843 [17:26<00:00,  2.72batch/s, train accuracy:0.501, loss:0.321, prec:0.562, rec:0.501]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:44<00:00, 11.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8944668769836426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|████████| 2843/2843 [16:58<00:00,  2.79batch/s, train accuracy:0.579, loss:0.269, prec:0.638, rec:0.579]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [01:48<00:00,  4.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9049273133277893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|████████| 2843/2843 [16:59<00:00,  2.79batch/s, train accuracy:0.608, loss:0.246, prec:0.662, rec:0.608]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:44<00:00, 11.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.915663480758667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|████████| 2843/2843 [16:54<00:00,  2.80batch/s, train accuracy:0.626, loss:0.232, prec:0.678, rec:0.626]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:44<00:00, 11.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9185037016868591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|████████| 2843/2843 [17:06<00:00,  2.77batch/s, train accuracy:0.644, loss:0.219, prec:0.688, rec:0.644]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:44<00:00, 11.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9235542416572571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|████████| 2843/2843 [16:55<00:00,  2.80batch/s, train accuracy:0.650, loss:0.210, prec:0.694, rec:0.650]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [02:24<00:00,  3.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9271314740180969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|████████| 2843/2843 [16:54<00:00,  2.80batch/s, train accuracy:0.662, loss:0.203, prec:0.704, rec:0.662]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:44<00:00, 11.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.929146945476532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|████████| 2843/2843 [16:56<00:00,  2.80batch/s, train accuracy:0.666, loss:0.194, prec:0.702, rec:0.666]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:44<00:00, 11.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9277873039245605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|████████| 2843/2843 [16:55<00:00,  2.80batch/s, train accuracy:0.674, loss:0.187, prec:0.711, rec:0.674]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:44<00:00, 11.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.931045413017273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|███████| 2843/2843 [16:56<00:00,  2.80batch/s, train accuracy:0.686, loss:0.180, prec:0.719, rec:0.686]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [01:54<00:00,  4.39batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9302316904067993\n",
      "training accuracy:0.686, precision:0.719, recall:0.686, f1:0.702\n",
      "validation accuracy:0.670, precision:0.708, recall:0.670, f1:0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import efficientnet_b4\n",
    "\n",
    "model = efficientnet_b4(weights='DEFAULT')\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.4),\n",
    "    nn.Linear(1792, NCLASS)\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "#ce = nn.CrossEntropyLoss()\n",
    "focal = FocalLoss(gamma=FOCAL_GAMMA, alpha=FOCAL_ALPHA)\n",
    "adam = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "history = {\n",
    "    'loss' : [],\n",
    "    'acc' : [],\n",
    "    'prec' : [],\n",
    "    'rec' : [],\n",
    "    'f1' : [],\n",
    "    'val_loss' : [],\n",
    "    'val_acc' : [],\n",
    "    'val_prec' : [],\n",
    "    'val_rec' : [],\n",
    "    'val_f1' : [],\n",
    "    'rocauc' : []\n",
    "}\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    train_history = model_train(train_dataloader, model, focal, adam, i+1)\n",
    "    val_result = model_predict(val_dataloader, model, focal, silent=False)\n",
    "\n",
    "    history = add_history(history, train_history, val_result)\n",
    "\n",
    "print_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1:   0%|                                                                            | 0/2843 [00:07<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 12.00 GiB total capacity; 11.09 GiB already allocated; 0 bytes free; 11.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m history \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m : [],\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m : [],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrocauc\u001b[39m\u001b[38;5;124m'\u001b[39m : []\n\u001b[0;32m     26\u001b[0m }\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCH):\n\u001b[1;32m---> 28\u001b[0m     train_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfocal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     val_result \u001b[38;5;241m=\u001b[39m model_predict(val_dataloader, model, focal, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     31\u001b[0m     history \u001b[38;5;241m=\u001b[39m add_history(history, train_history, val_result)\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mmodel_train\u001b[1;34m(dataloader, model, loss_func, optimizer, current_epoch)\u001b[0m\n\u001b[0;32m     15\u001b[0m prog_bar \u001b[38;5;241m=\u001b[39m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m prog_bar:\n\u001b[1;32m---> 17\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     target \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m#pred = F.softmax(pred, dim=1)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m#print(pred.size())\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torchvision\\models\\efficientnet.py:355\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torchvision\\models\\efficientnet.py:345\u001b[0m, in \u001b[0;36mEfficientNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 345\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[0;32m    348\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torchvision\\models\\efficientnet.py:165\u001b[0m, in \u001b[0;36mMBConv.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 165\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_res_connect:\n\u001b[0;32m    167\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstochastic_depth(result)\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\nn\\functional.py:2438\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2436\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2439\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2440\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 12.00 GiB total capacity; 11.09 GiB already allocated; 0 bytes free; 11.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from torchvision.models import efficientnet_b6\n",
    "\n",
    "model = efficientnet_b6(weights='DEFAULT')\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(2304, NCLASS)\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "#ce = nn.CrossEntropyLoss()\n",
    "focal = FocalLoss(gamma=FOCAL_GAMMA, alpha=FOCAL_ALPHA)\n",
    "adam = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "history = {\n",
    "    'loss' : [],\n",
    "    'acc' : [],\n",
    "    'prec' : [],\n",
    "    'rec' : [],\n",
    "    'f1' : [],\n",
    "    'val_loss' : [],\n",
    "    'val_acc' : [],\n",
    "    'val_prec' : [],\n",
    "    'val_rec' : [],\n",
    "    'val_f1' : [],\n",
    "    'rocauc' : []\n",
    "}\n",
    "for i in range(EPOCH):\n",
    "    train_history = model_train(train_dataloader, model, focal, adam, i+1)\n",
    "    val_result = model_predict(val_dataloader, model, focal, silent=False)\n",
    "\n",
    "    history = add_history(history, train_history, val_result)\n",
    "\n",
    "print_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ShuffleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|████████| 2843/2843 [02:59<00:00, 15.84batch/s, train accuracy:0.492, loss:0.455, prec:0.563, rec:0.492]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:11<00:00, 41.84batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8823245763778687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|████████| 2843/2843 [02:57<00:00, 16.05batch/s, train accuracy:0.559, loss:0.399, prec:0.636, rec:0.559]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 40.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8975889086723328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|████████| 2843/2843 [02:56<00:00, 16.10batch/s, train accuracy:0.584, loss:0.378, prec:0.655, rec:0.584]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 41.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9067186713218689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|████████| 2843/2843 [03:06<00:00, 15.21batch/s, train accuracy:0.599, loss:0.364, prec:0.663, rec:0.599]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 41.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9094777703285217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|████████| 2843/2843 [03:28<00:00, 13.63batch/s, train accuracy:0.602, loss:0.354, prec:0.665, rec:0.602]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 41.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.914448618888855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|████████| 2843/2843 [03:14<00:00, 14.59batch/s, train accuracy:0.614, loss:0.345, prec:0.677, rec:0.614]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 40.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9164899587631226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|████████| 2843/2843 [03:09<00:00, 15.02batch/s, train accuracy:0.625, loss:0.336, prec:0.682, rec:0.625]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 41.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9173678755760193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|████████| 2843/2843 [03:44<00:00, 12.67batch/s, train accuracy:0.628, loss:0.332, prec:0.683, rec:0.628]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 41.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9191175699234009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|████████| 2843/2843 [02:48<00:00, 16.91batch/s, train accuracy:0.634, loss:0.326, prec:0.688, rec:0.634]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 38.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9241763353347778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|███████| 2843/2843 [02:47<00:00, 16.98batch/s, train accuracy:0.636, loss:0.322, prec:0.691, rec:0.636]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 41.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9187948703765869\n",
      "training accuracy:0.636, precision:0.691, recall:0.636, f1:0.662\n",
      "validation accuracy:0.661, precision:0.685, recall:0.661, f1:0.673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import shufflenet_v2_x1_0\n",
    "\n",
    "model = shufflenet_v2_x1_0(weights='DEFAULT')\n",
    "model.fc = nn.Linear(1024, NCLASS)\n",
    "#freeze_layer(model, freeze_pct=0.2)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "#loss_weight = torch.cuda.FloatTensor([0.15, 1.0, 1.0, 1.0])\n",
    "#ce = nn.CrossEntropyLoss(weight=loss_weight)\n",
    "focal = FocalLoss(gamma=FOCAL_GAMMA, alpha=FOCAL_ALPHA)\n",
    "adam = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "#adam = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
    "\n",
    "history = {\n",
    "    'loss' : [],\n",
    "    'acc' : [],\n",
    "    'prec' : [],\n",
    "    'rec' : [],\n",
    "    'f1' : [],\n",
    "    'val_loss' : [],\n",
    "    'val_acc' : [],\n",
    "    'val_prec' : [],\n",
    "    'val_rec' : [],\n",
    "    'val_f1' : [],\n",
    "    'rocauc' : []\n",
    "}\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    train_history = model_train(train_dataloader, model, focal, adam, i+1)\n",
    "    val_result = model_predict(val_dataloader, model, focal, silent=False)\n",
    "\n",
    "    history = add_history(history, train_history, val_result)\n",
    "\n",
    "print_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/shufflenetv2_x0.5-f707e7126e.pth\" to C:\\Users\\Edy Irwansyah/.cache\\torch\\hub\\checkpoints\\shufflenetv2_x0.5-f707e7126e.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 5.28M/5.28M [00:01<00:00, 3.04MB/s]\n",
      "Epoch: 1: 100%|████████| 2843/2843 [23:30<00:00,  2.02batch/s, train accuracy:0.477, loss:0.686, prec:0.548, rec:0.477]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [04:10<00:00,  2.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8706121444702148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|████████| 2843/2843 [02:50<00:00, 16.64batch/s, train accuracy:0.541, loss:0.614, prec:0.624, rec:0.541]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:13<00:00, 38.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8807520866394043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|████████| 2843/2843 [02:55<00:00, 16.23batch/s, train accuracy:0.568, loss:0.583, prec:0.643, rec:0.568]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 40.30batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8929417133331299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|████████| 2843/2843 [02:48<00:00, 16.88batch/s, train accuracy:0.580, loss:0.564, prec:0.652, rec:0.580]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 40.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8946371078491211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|████████| 2843/2843 [02:54<00:00, 16.27batch/s, train accuracy:0.591, loss:0.551, prec:0.663, rec:0.591]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 40.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9015276432037354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|████████| 2843/2843 [02:48<00:00, 16.90batch/s, train accuracy:0.602, loss:0.539, prec:0.670, rec:0.602]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 41.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9053434133529663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|████████| 2843/2843 [02:57<00:00, 16.02batch/s, train accuracy:0.608, loss:0.532, prec:0.672, rec:0.608]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 39.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9074108004570007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|████████| 2843/2843 [02:46<00:00, 17.07batch/s, train accuracy:0.616, loss:0.522, prec:0.682, rec:0.616]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 40.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9090672731399536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|████████| 2843/2843 [02:59<00:00, 15.84batch/s, train accuracy:0.616, loss:0.517, prec:0.680, rec:0.616]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 40.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9105983972549438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|███████| 2843/2843 [02:47<00:00, 16.99batch/s, train accuracy:0.624, loss:0.510, prec:0.686, rec:0.624]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:12<00:00, 40.52batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9150599241256714\n",
      "training accuracy:0.624, precision:0.686, recall:0.624, f1:0.653\n",
      "validation accuracy:0.633, precision:0.674, recall:0.633, f1:0.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import shufflenet_v2_x0_5\n",
    "\n",
    "model = shufflenet_v2_x0_5(weights='DEFAULT')\n",
    "model.fc = nn.Linear(1024, NCLASS)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "focal = FocalLoss(gamma=FOCAL_GAMMA, alpha=FOCAL_ALPHA)\n",
    "adam = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "history = {\n",
    "    'loss' : [],\n",
    "    'acc' : [],\n",
    "    'prec' : [],\n",
    "    'rec' : [],\n",
    "    'f1' : [],\n",
    "    'val_loss' : [],\n",
    "    'val_acc' : [],\n",
    "    'val_prec' : [],\n",
    "    'val_rec' : [],\n",
    "    'val_f1' : [],\n",
    "    'rocauc' : []\n",
    "}\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    train_history = model_train(train_dataloader, model, focal, adam, i+1)\n",
    "    val_result = model_predict(val_dataloader, model, focal, silent=False)\n",
    "\n",
    "    history = add_history(history, train_history, val_result)\n",
    "\n",
    "print_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import shufflenet_v2_x1_5\n",
    "\n",
    "model = shufflenet_v2_x1_5(weights='DEFAULT')\n",
    "model.fc = nn.Linear(1024, NCLASS)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "#loss_weight = torch.cuda.FloatTensor([0.15, 1.0, 1.0, 1.0])\n",
    "#ce = nn.CrossEntropyLoss(weight=loss_weight)\n",
    "focal = FocalLoss(gamma=FOCAL_GAMMA, alpha=FOCAL_ALPHA)\n",
    "adam = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "history = {\n",
    "    'loss' : [],\n",
    "    'acc' : [],\n",
    "    'prec' : [],\n",
    "    'rec' : [],\n",
    "    'f1' : [],\n",
    "    'val_loss' : [],\n",
    "    'val_acc' : [],\n",
    "    'val_prec' : [],\n",
    "    'val_rec' : [],\n",
    "    'val_f1' : [],\n",
    "    'rocauc' : []\n",
    "}\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    train_history = model_train(train_dataloader, model, focal, adam, i+1)\n",
    "    val_result = model_predict(val_dataloader, model, focal, silent=False)\n",
    "\n",
    "    history = add_history(history, train_history, val_result)\n",
    "\n",
    "print_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/shufflenetv2_x2_0-8be3c8ee.pth\" to C:\\Users\\Edy Irwansyah/.cache\\torch\\hub\\checkpoints\\shufflenetv2_x2_0-8be3c8ee.pth\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 28.4M/28.4M [00:40<00:00, 734kB/s]\n",
      "Epoch: 1: 100%|████████| 2843/2843 [08:28<00:00,  5.59batch/s, train accuracy:0.489, loss:0.680, prec:0.565, rec:0.489]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:29<00:00, 17.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8615797758102417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|████████| 2843/2843 [04:03<00:00, 11.68batch/s, train accuracy:0.556, loss:0.605, prec:0.629, rec:0.556]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:16<00:00, 30.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8887726068496704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|████████| 2843/2843 [03:55<00:00, 12.09batch/s, train accuracy:0.578, loss:0.573, prec:0.652, rec:0.578]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:16<00:00, 30.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9012756943702698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|████████| 2843/2843 [03:58<00:00, 11.94batch/s, train accuracy:0.592, loss:0.550, prec:0.659, rec:0.592]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:16<00:00, 30.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8989168405532837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|████████| 2843/2843 [03:58<00:00, 11.92batch/s, train accuracy:0.609, loss:0.533, prec:0.671, rec:0.609]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:16<00:00, 30.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9073429107666016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|████████| 2843/2843 [04:00<00:00, 11.83batch/s, train accuracy:0.617, loss:0.521, prec:0.677, rec:0.617]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:16<00:00, 30.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9167101383209229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|████████| 2843/2843 [03:56<00:00, 12.01batch/s, train accuracy:0.626, loss:0.510, prec:0.682, rec:0.626]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:16<00:00, 30.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9168139696121216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|████████| 2843/2843 [03:57<00:00, 11.99batch/s, train accuracy:0.632, loss:0.500, prec:0.686, rec:0.632]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:16<00:00, 30.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9177054166793823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|████████| 2843/2843 [03:58<00:00, 11.93batch/s, train accuracy:0.639, loss:0.492, prec:0.693, rec:0.639]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:16<00:00, 30.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9217766523361206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|███████| 2843/2843 [03:56<00:00, 12.01batch/s, train accuracy:0.640, loss:0.482, prec:0.696, rec:0.640]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:16<00:00, 30.56batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.9191476106643677\n",
      "training accuracy:0.640, precision:0.696, recall:0.640, f1:0.667\n",
      "validation accuracy:0.640, precision:0.689, recall:0.640, f1:0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import shufflenet_v2_x2_0\n",
    "\n",
    "model = shufflenet_v2_x2_0(weights='DEFAULT')\n",
    "model.fc = nn.Linear(2048, NCLASS)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "focal = FocalLoss(gamma=FOCAL_GAMMA, alpha=FOCAL_ALPHA)\n",
    "adam = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "history = {\n",
    "    'loss' : [],\n",
    "    'acc' : [],\n",
    "    'prec' : [],\n",
    "    'rec' : [],\n",
    "    'f1' : [],\n",
    "    'val_loss' : [],\n",
    "    'val_acc' : [],\n",
    "    'val_prec' : [],\n",
    "    'val_rec' : [],\n",
    "    'val_f1' : [],\n",
    "    'rocauc' : []\n",
    "}\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    train_history = model_train(train_dataloader, model, focal, adam, i+1)\n",
    "    val_result = model_predict(val_dataloader, model, focal, silent=False)\n",
    "\n",
    "    history = add_history(history, train_history, val_result)\n",
    "\n",
    "print_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:107004\n",
      "training:90953 validation:16051\n"
     ]
    }
   ],
   "source": [
    "# dataset param\n",
    "IMG_SIZE = (299, 299)\n",
    "\n",
    "# augmentations                         \n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(p=0.2),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# creating dataset and loader using image folder\n",
    "full_dataset = ImageFolder(DATA_PATH, transform=train_transform)\n",
    "full_dataset_test = ImageFolder(DATA_PATH, transform=test_transform)\n",
    "\n",
    "data_idx = np.arange(len(full_dataset))\n",
    "train_idx, val_idx = train_test_split(data_idx, test_size=VAL_SPLIT, random_state=100)\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "val_dataset = Subset(full_dataset_test, val_idx)\n",
    "print(f\"total:{len(full_dataset)}\\ntraining:{len(train_dataset)} validation:{len(val_dataset)}\")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True, num_workers=NUMWORKERS, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, BATCH_SIZE, num_workers=NUMWORKERS, pin_memory=True)\n",
    "\n",
    "def model_train(dataloader, model, loss_func, optimizer, current_epoch):\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    avg_prec = 0\n",
    "    avg_rec = 0\n",
    "    cur_len = 1\n",
    "\n",
    "    prog_bar = tqdm(dataloader, desc=f'Epoch: {current_epoch}', unit='batch')\n",
    "    for x,y in prog_bar:\n",
    "        pred, _ = model(x.to(DEVICE))\n",
    "        target = y.to(DEVICE)\n",
    "        #pred = F.softmax(pred, dim=1)\n",
    "        #print(pred.size())\n",
    "        loss = loss_func(pred, target)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # eval\n",
    "        acc = MF.accuracy(pred, target, task='multiclass', average='macro', num_classes=NCLASS, top_k=1, validate_args=False)\n",
    "        prec = MF.precision(pred, target, task='multiclass', average='macro', num_classes=NCLASS, top_k=1, validate_args=False)\n",
    "        rec = MF.recall(pred, target, task='multiclass', average='macro', num_classes=NCLASS, top_k=1, validate_args=False)\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "        avg_acc += acc\n",
    "        avg_prec += prec\n",
    "        avg_rec += rec\n",
    "\n",
    "        prog_bar.set_postfix_str(f'train accuracy:{avg_acc/cur_len:.3f}, loss:{avg_loss/cur_len:.3f}, prec:{avg_prec/cur_len:.3f}, rec:{avg_rec/cur_len:.3f}')\n",
    "        cur_len += 1\n",
    "    \n",
    "    # count avg\n",
    "    data_len = len(dataloader)\n",
    "    avg_loss /= data_len\n",
    "    avg_acc /= data_len\n",
    "    avg_prec /= data_len\n",
    "    avg_rec /= data_len\n",
    "\n",
    "    f1 = (2 * avg_prec * avg_rec) / (avg_prec + avg_rec)\n",
    "\n",
    "    history = {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy' : avg_acc,\n",
    "        'precision' : avg_prec,\n",
    "        'recall' : avg_rec,\n",
    "        'f1_score' : f1\n",
    "    }\n",
    "\n",
    "    return history\n",
    "\n",
    "def model_predict(dataloader, model, loss_func, silent=True, save_prediction=False):\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    avg_prec = 0\n",
    "    avg_rec = 0\n",
    "    \n",
    "    predictions = torch.tensor([]).to(DEVICE)\n",
    "    targets = torch.tensor([], dtype=torch.int64).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x,y in tqdm(dataloader, desc='Predicting', unit='batch', disable=silent):\n",
    "            pred, _ = model(x.to(DEVICE))\n",
    "            target = y.to(DEVICE)\n",
    "            #pred = F.softmax(pred, dim=1)\n",
    "            loss = loss_func(pred, target)\n",
    "\n",
    "            acc = MF.accuracy(pred, target, task='multiclass', average='macro', num_classes=NCLASS, top_k=1, validate_args=False)\n",
    "            prec = MF.precision(pred, target, task='multiclass', average='macro', num_classes=NCLASS, top_k=1, validate_args=False)\n",
    "            rec = MF.recall(pred, target, task='multiclass', average='macro', num_classes=NCLASS, top_k=1, validate_args=False)\n",
    "            \n",
    "            avg_loss += loss.item()\n",
    "            avg_acc += acc\n",
    "            avg_prec += prec\n",
    "            avg_rec += rec\n",
    "            \n",
    "            predictions = torch.cat((predictions, pred), dim=0)\n",
    "            targets = torch.cat((targets, target), dim=0)\n",
    "        \n",
    "    data_len = len(dataloader)\n",
    "    avg_loss /= data_len\n",
    "    avg_acc /= data_len\n",
    "    avg_prec /= data_len\n",
    "    avg_rec /= data_len\n",
    "\n",
    "    f1 = (2 * avg_prec * avg_rec) / (avg_prec + avg_rec)\n",
    "    \n",
    "    rocauc = MF.auroc(predictions, targets, task='multiclass', num_classes=NCLASS, average='macro')\n",
    "    if not silent:\n",
    "        print(f\"roc-auc:{rocauc.item()}\")\n",
    "\n",
    "    result = {\n",
    "        'predictions' : predictions if save_prediction else None,\n",
    "        'targets' : targets if save_prediction else None,\n",
    "        'rocauc' : rocauc,\n",
    "        'loss': avg_loss,\n",
    "        'accuracy' : avg_acc,\n",
    "        'precision' : avg_prec,\n",
    "        'recall' : avg_rec,\n",
    "        'f1_score' : f1\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to C:\\Users\\Edy Irwansyah/.cache\\torch\\hub\\checkpoints\\inception_v3_google-0cc3c7bd.pth\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 104M/104M [04:23<00:00, 413kB/s]\n",
      "Epoch: 1: 100%|████████| 2843/2843 [19:59<00:00,  2.37batch/s, train accuracy:0.394, loss:0.801, prec:0.445, rec:0.394]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [02:02<00:00,  4.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8141070008277893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|████████| 2843/2843 [15:32<00:00,  3.05batch/s, train accuracy:0.470, loss:0.710, prec:0.557, rec:0.470]\n",
      "Predicting: 100%|█████████████████████████████████████████████████████████████████| 502/502 [00:48<00:00, 10.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc:0.8466964960098267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3:  15%|█▎       | 417/2843 [02:21<13:44,  2.94batch/s, train accuracy:0.504, loss:0.681, prec:0.593, rec:0.504]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m history \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m : [],\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m : [],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrocauc\u001b[39m\u001b[38;5;124m'\u001b[39m : []\n\u001b[0;32m     23\u001b[0m }\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCH):\n\u001b[1;32m---> 26\u001b[0m     train_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfocal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     val_result \u001b[38;5;241m=\u001b[39m model_predict(val_dataloader, model, focal, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m     history \u001b[38;5;241m=\u001b[39m add_history(history, train_history, val_result)\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mmodel_train\u001b[1;34m(dataloader, model, loss_func, optimizer, current_epoch)\u001b[0m\n\u001b[0;32m     49\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     50\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 51\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# eval\u001b[39;00m\n\u001b[0;32m     54\u001b[0m acc \u001b[38;5;241m=\u001b[39m MF\u001b[38;5;241m.\u001b[39maccuracy(pred, target, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39mNCLASS, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, validate_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\optim\\optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\optim\\adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\optim\\adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Users\\Edy Irwansyah\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\optim\\adam.py:263\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    262\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m--> 263\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable:\n\u001b[0;32m    266\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision.models import inception_v3\n",
    "\n",
    "model = inception_v3(weights='DEFAULT')\n",
    "model.fc = nn.Linear(2048, NCLASS)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "#ce = nn.CrossEntropyLoss()\n",
    "focal = FocalLoss(gamma=FOCAL_GAMMA, alpha=FOCAL_ALPHA)\n",
    "adam = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "history = {\n",
    "    'loss' : [],\n",
    "    'acc' : [],\n",
    "    'prec' : [],\n",
    "    'rec' : [],\n",
    "    'f1' : [],\n",
    "    'val_loss' : [],\n",
    "    'val_acc' : [],\n",
    "    'val_prec' : [],\n",
    "    'val_rec' : [],\n",
    "    'val_f1' : [],\n",
    "    'rocauc' : []\n",
    "}\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    train_history = model_train(train_dataloader, model, focal, adam, i+1)\n",
    "    val_result = model_predict(val_dataloader, model, focal, silent=False)\n",
    "\n",
    "    history = add_history(history, train_history, val_result)\n",
    "\n",
    "print_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9c39c1d352b1b33b9773a03fde87dd70d7a73bf47607333d53e9195008013099"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
